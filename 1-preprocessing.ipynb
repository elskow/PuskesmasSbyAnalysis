{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T06:28:33.516336Z",
     "start_time": "2024-06-21T06:28:33.464141Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_puskesmas = pd.read_csv(\"review-data.csv\")\n",
    "\n",
    "data_puskesmas.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             reviewer_name     rating  \\\n",
       "0              Mira Diah V  5 bintang   \n",
       "1  Ranitya Dewi Ayu Sadian  1 bintang   \n",
       "2                  Mas Bri  4 bintang   \n",
       "3             Yuliasti Ika  5 bintang   \n",
       "4               Yusup Jaya  1 bintang   \n",
       "\n",
       "                                         review_text       puskesmas_name  \n",
       "0  Pelayanan di poli KIA bagus&informatif sekali....  Puskesmas Simomulyo  \n",
       "1  Pelayanan poli KIA lama sekaliâ€¦\\nKamis pagi se...  Puskesmas Simomulyo  \n",
       "2  Menurut saya sudah bagus untuk mau yang mau be...  Puskesmas Simomulyo  \n",
       "3  Puskesmas dengan pelayanan yang baik sekali, s...  Puskesmas Simomulyo  \n",
       "4  Pelayanan tambah lelet, mohon managentnya di p...  Puskesmas Simomulyo  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>puskesmas_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mira Diah V</td>\n",
       "      <td>5 bintang</td>\n",
       "      <td>Pelayanan di poli KIA bagus&amp;informatif sekali....</td>\n",
       "      <td>Puskesmas Simomulyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ranitya Dewi Ayu Sadian</td>\n",
       "      <td>1 bintang</td>\n",
       "      <td>Pelayanan poli KIA lama sekaliâ€¦\\nKamis pagi se...</td>\n",
       "      <td>Puskesmas Simomulyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mas Bri</td>\n",
       "      <td>4 bintang</td>\n",
       "      <td>Menurut saya sudah bagus untuk mau yang mau be...</td>\n",
       "      <td>Puskesmas Simomulyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yuliasti Ika</td>\n",
       "      <td>5 bintang</td>\n",
       "      <td>Puskesmas dengan pelayanan yang baik sekali, s...</td>\n",
       "      <td>Puskesmas Simomulyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yusup Jaya</td>\n",
       "      <td>1 bintang</td>\n",
       "      <td>Pelayanan tambah lelet, mohon managentnya di p...</td>\n",
       "      <td>Puskesmas Simomulyo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_puskesmas[\"rating\"] = data_puskesmas[\"rating\"].str.replace(\" bintang\", \"\")\n",
    "data_puskesmas[\"rating\"] = data_puskesmas[\"rating\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5708/789531257.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data_puskesmas = data_puskesmas.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# remove extra spaces in the data\n",
    "data_puskesmas = data_puskesmas.applymap(\n",
    "    lambda x: x.strip() if isinstance(x, str) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in data_puskesmas: \n",
      "reviewer_name        0\n",
      "rating               0\n",
      "review_text       4190\n",
      "puskesmas_name       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Null values in data_puskesmas: \\n{data_puskesmas.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in data_puskesmas: \n",
      "reviewer_name     0\n",
      "rating            0\n",
      "review_text       0\n",
      "puskesmas_name    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# drop row with null values in review_text\n",
    "data_puskesmas = data_puskesmas.dropna(subset=[\"review_text\"])\n",
    "\n",
    "print(f\"Null values in data_puskesmas: \\n{data_puskesmas.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating 5:\n",
      "Pelayanan di poli KIA bagus&informatif sekali. Anak saya imunisasi hari ini, meskipun anaknya rewel&tidak kooperatif tetapi tetap dilayani dgn sabarðŸ™ dan diberi tata cara waktu dirumah untuk penanganan post imunisasi. Terimakasih banyak untuk para nakesnyaðŸ™ â€¦\n",
      "\n",
      "Rating 1:\n",
      "Pelayanan poli KIA lama sekaliâ€¦\n",
      "Kamis pagi sekitar pukul 07.35 sy sudah di puskesmas, awalnya sy daftar di poli umum, pelayanan cepat, sekitar pukul 08.14 sy di rujuk intern di poli KIA, waktu sy sampai nomor antrian sudah 28 tetapi tdk segera dilayani,sekitar 10menit kemudian baru no 28 dipanggil kembali dan masuk. Tetapi tidak kunjung selesai smpai pukul 08.52. Lalu di panggil kembali antrian dari awal no.10, sebenarnya mekanismenya saja sdh tidak beraturan, kebetulan sy dapat rujukan intern no 36. Kira2 sy harus menunggu smpai brp lama? Sedangkan masih harus ada aktivitas setelah itu. Mohon perbaikan pelayanannya.. 1 pasien harusnya paling lama 10 menit dan continue,ini lebih dari itu dan setelah pasien keluar jedanya terlalu lama untuk menunggu.\n",
      "Padahal awal sy datang pasien masih 2 smpai sy belum dilayani pasien sudah padat.\n",
      "Dan di pukul 09.19 masih nomer 28 dan masih melayani pasien no awal yg baru datang. Akhirnya sy pulgâ€¦ karena sy ijin kantor hanya smpai pukul 10.\n",
      "\n",
      "Rating 4:\n",
      "Menurut saya sudah bagus untuk mau yang mau berobat di sini. bisa daftar dulu secara online dengan alamat website yang sudah atau yang mudah dicari di Google.\n",
      "Saya berikan apresiasi untuk tukang parkir motor yang ada di depan karena sangat gercep sekali membantu pasien yang berkunjung di Puskesmas ini. harga parkir motor cuma 2000. kemudian untuk pelayanan sejauh ini cukup baik, jadi ketika pasien sudah daftar secara online, nanti konfirmasi aja ke bagian pendaftaran dan biasanya langsung diarahkan ke tempat duduk kursi tunggu. di situ terdapat monitor antrian, kita bisa Maman tahu kapan waktu kita akan dipanggil.\n",
      "\n",
      "Rating 2:\n",
      "Pelayanan semakin jelek... Dokternya lambat. Apalagi di poli umum... Antrinya  lamaaaaa banget.\n",
      "\n",
      "Rating 3:\n",
      "berkunjung untuk penerbitan rujukan ke klinik mata, akses dipermudah dan pelayanan semakin baik. terima kasih\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show 1 example of review_text each rating\n",
    "for rate in data_puskesmas[\"rating\"].unique():\n",
    "    print(f\"Rating {rate}:\")\n",
    "    print(data_puskesmas[data_puskesmas[\"rating\"] == rate][\"review_text\"].iloc[0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "import requests\n",
    "\n",
    "\"\"\"\n",
    "For testing regex you can use this website: https://regex101.com/\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def rm_emoji(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"\n",
    "        \"\\U0001F300-\\U0001F5FF\"\n",
    "        \"\\U0001F680-\\U0001F6FF\"\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"\n",
    "        \"\\U00002500-\\U00002BEF\"\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"\\U0001f926-\\U0001f937\"\n",
    "        \"\\U00010000-\\U0010ffff\"\n",
    "        \"\\u200d\"\n",
    "        \"\\u2640-\\u2642\"\n",
    "        \"\\u2600-\\u2B55\"\n",
    "        \"\\u23cf\"\n",
    "        \"\\u23e9\"\n",
    "        \"\\u231a\"\n",
    "        \"\\u3030\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    return emoji_pattern.sub(r\"\", text)\n",
    "\n",
    "\n",
    "# Remove punctuations, links, hashtags, and other unnecessary characters\n",
    "def rm_unnecessary(text):\n",
    "    text = re.sub(r\"#\\S+\", \"\", text)  # Rm hashtags\n",
    "    text = re.sub(r\"(\\.|-|_|\\,)\\1+\", r\"\\1\", text)  # Rm repeating punctuations\n",
    "    text = re.sub(r\"([aiueo])\\1{2,}\", r\"\\1\", text)  # Rm repeating vowels\n",
    "    text = re.sub(r\" -\\S+\", \"\", text)  # Remove words preceded by a space and a hyphen\n",
    "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text)  # Rm links\n",
    "    text = re.sub(r\"&\\w+;\", \"\", text)  # Rm HTML entities\n",
    "    text = re.sub(r\"[^\\x00-\\x7f]\", r\"\", text)  # Rm non-ASCII\n",
    "    text = (\n",
    "        text.replace(\"\\r\", \"\").replace(\"\\n\", \" \").replace(\"\\n\", \" \").lower()\n",
    "    )  # Rm new lines\n",
    "    stopper = (\n",
    "        string.punctuation + \"Ãƒ\" + \"Â±\" + \"Ã£\" + \"Â¼\" + \"Ã¢\" + \"Â»\" + \"Â§\"\n",
    "    )  # Rm punctuation\n",
    "    table = str.maketrans(\"\", \"\", stopper)\n",
    "    text = text.translate(table)\n",
    "    text = re.sub(r\"\\d\", \"\", text)  # Rm numbers\n",
    "    return text\n",
    "\n",
    "\n",
    "def rm_multiple_space(text):\n",
    "    return re.sub(\"\\s\\s+\", \" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_puskesmas[\"cleaned_review_text\"] = data_puskesmas[\"review_text\"].apply(\n",
    "    lambda x: rm_multiple_space(rm_unnecessary(rm_emoji(x)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize slang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nasa's Alay Indonesian Slang Words: (15006, 7)\n",
      "Fendi Indonesian Stop Words: (1514, 2)\n",
      "Okky Indonesian Stop Words: (15167, 2)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dictionary for Indonesian Slang Words (Bahasa Alay) were downloaded from https://github.com/nasalsabila/kamus-alay\n",
    "\"\"\"\n",
    "\n",
    "nasalsabila_indonesian_slang_words = pd.read_csv(\n",
    "    f\"data/colloquial-indonesian-lexicon.csv\", sep=\",\"\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Dictionary for Indonesian Slang Words (Bahasa Alay) were downloaded from https://github.com/fendiirfan/Kamus-Alay\n",
    "\"\"\"\n",
    "\n",
    "fendi_indonesian_slang_words = pd.read_csv(f\"data/Kamus-Alay.csv\", sep=\",\")\n",
    "\n",
    "\"\"\"\n",
    "Dictionary for Indonesian Slang Words (Bahasa Alay) were downloaded from https://github.com/okkyibrohim/id-multi-label-hate-speech-and-abusive-language-detection\n",
    "\"\"\"\n",
    "\n",
    "okky_file = open(f\"data/new_kamusalay.csv\", \"r\", encoding=\"ISO-8859-1\")\n",
    "okky_indonesian_slang_words = []\n",
    "for line in okky_file:\n",
    "    line = line.strip().split(\",\")\n",
    "    okky_indonesian_slang_words.append(line)\n",
    "okky_indonesian_slang_words = pd.DataFrame(\n",
    "    okky_indonesian_slang_words, columns=[\"slang\", \"formal\"]\n",
    ")\n",
    "\n",
    "print(f\"Nasa's Alay Indonesian Slang Words: {nasalsabila_indonesian_slang_words.shape}\")\n",
    "print(f\"Fendi Indonesian Stop Words: {fendi_indonesian_slang_words.shape}\")\n",
    "print(f\"Okky Indonesian Stop Words: {okky_indonesian_slang_words.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['slang', 'formal'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "rename_dict = {\"kataAlay\": \"slang\", \"kataBaik\": \"formal\"}\n",
    "fendi_indonesian_slang_words.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "print(fendi_indonesian_slang_words.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['slang', 'formal'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "not_to_drop = [\"slang\", \"formal\"]\n",
    "nasalsabila_indonesian_slang_words.drop(\n",
    "    columns=[\n",
    "        col\n",
    "        for col in nasalsabila_indonesian_slang_words.columns\n",
    "        if col not in not_to_drop\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "print(nasalsabila_indonesian_slang_words.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Indonesian Slang Words: (16346, 2)\n"
     ]
    }
   ],
   "source": [
    "indonesian_slang_words = pd.concat(\n",
    "    [\n",
    "        nasalsabila_indonesian_slang_words,\n",
    "        fendi_indonesian_slang_words,\n",
    "        okky_indonesian_slang_words,\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "indonesian_slang_words.drop_duplicates(subset=[\"slang\"], inplace=True)\n",
    "indonesian_slang_words = indonesian_slang_words.dropna()\n",
    "\n",
    "print(f\"Combined Indonesian Slang Words: {indonesian_slang_words.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "slang_dict = defaultdict(str)\n",
    "for slang, formal in zip(\n",
    "    indonesian_slang_words[\"slang\"], indonesian_slang_words[\"formal\"]\n",
    "):\n",
    "    slang_dict[slang] = formal\n",
    "\n",
    "\n",
    "def normalize_slang(text):\n",
    "    return \" \".join(\n",
    "        [slang_dict[word] if word in slang_dict else word for word in text.split()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_puskesmas[\"cleaned_review_text\"] = data_puskesmas[\"cleaned_review_text\"].apply(\n",
    "    normalize_slang\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q nlp-id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_id.lemmatizer import Lemmatizer\n",
    "\n",
    "lemmatizer = Lemmatizer()\n",
    "\n",
    "\n",
    "def lemmatize(text):\n",
    "    return lemmatizer.lemmatize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_puskesmas[\"cleaned_review_text\"] = data_puskesmas[\"cleaned_review_text\"].apply(\n",
    "    lemmatize\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Stop Word List in bahasa were downloaded from https://www.kaggle.com/datasets/oswinrh/indonesian-stoplist\n",
    "\"\"\"\n",
    "\n",
    "indonesian_stopwords = []\n",
    "with open(f\"data/stopwordbahasa.txt\", \"r\") as f:\n",
    "    indonesian_stopwords = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stopwords: 936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/helmyl/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "english_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "stopwords = set(english_stopwords).union(set(indonesian_stopwords))\n",
    "\n",
    "print(f\"Total stopwords: {len(stopwords)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_stopwords(text):\n",
    "    return \" \".join([word for word in text.split() if word not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_puskesmas[\"cleaned_review_text\"] = data_puskesmas[\"cleaned_review_text\"].apply(\n",
    "    rm_stopwords\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating 5:\n",
      "layan pol kia bagusinformatif anak imunisasi anak reweltidak kooperatif layan sabar tata rumah tangan post imunisasi terima kasih nakesnya\n",
      "\n",
      "Rating 1:\n",
      "layan pol kia kamis pagi puskesmas daftar pol layan cepat rujuk intern pol kia nomor antre dilayanisekitar menit panggil masuk kunjung selesai panggil antre mekanisme atur rujuk intern tunggu aktivitas mohon layan pasien menit continueini pasien jeda tunggu pasien layan pasien padat nomer layan pasien pulg izin kantor\n",
      "\n",
      "Rating 4:\n",
      "bagus obat daftar onlen alamat website mudah cari google ikan apresiasi tukang parkir motor gerak cepat bantu pasien kunjung puskesmas harga parkir motor layan pasien daftar onlen konfirmasi daftar langsung arah duduk kursi tunggu situ monitor antre maman panggil\n",
      "\n",
      "Rating 2:\n",
      "layan jelek dokter lambat pol antri banget\n",
      "\n",
      "Rating 3:\n",
      "kunjung terbit rujuk klinik mata akses mudah layan terima kasih\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show 1 example of review_text each rating\n",
    "for rate in data_puskesmas[\"rating\"].unique():\n",
    "    print(f\"Rating {rate}:\")\n",
    "    print(\n",
    "        data_puskesmas[data_puskesmas[\"rating\"] == rate][\"cleaned_review_text\"].iloc[0]\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect language for noise removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q fasttext-wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.bin.gz\n",
    "\n",
    "import os\n",
    "\n",
    "file_path = \"cc.id.300.bin\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.bin.gz -O cc.id.300.bin.gz -q\n",
    "    !gunzip cc.id.300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_path = \"lid.176.bin\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    !wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin -O lid.176.bin -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "from fasttext import FastText\n",
    "import numpy as np\n",
    "\n",
    "model_lang_detector = FastText.load_model(\"./lid.176.bin\")\n",
    "\n",
    "\n",
    "def detect_language(text):\n",
    "    return model_lang_detector.predict(text)[0][0].replace(\"__label__\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language\n",
      "id     8527\n",
      "en      695\n",
      "ms      321\n",
      "tr      289\n",
      "sv      114\n",
      "eo       86\n",
      "es       79\n",
      "ceb      62\n",
      "eu       54\n",
      "it       41\n",
      "fi       38\n",
      "nl       38\n",
      "hu       38\n",
      "jv       32\n",
      "lt       31\n",
      "fr       26\n",
      "ca       24\n",
      "la       24\n",
      "pl       22\n",
      "de       18\n",
      "no       17\n",
      "tl       16\n",
      "war      12\n",
      "su       12\n",
      "nds      11\n",
      "et       11\n",
      "pt        8\n",
      "lv        6\n",
      "sw        6\n",
      "bo        6\n",
      "sr        5\n",
      "hr        4\n",
      "min       4\n",
      "sl        4\n",
      "sk        3\n",
      "ro        3\n",
      "sq        3\n",
      "oc        2\n",
      "ja        2\n",
      "ur        2\n",
      "nn        1\n",
      "ga        1\n",
      "ht        1\n",
      "da        1\n",
      "cy        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_puskesmas[\"language\"] = data_puskesmas[\"cleaned_review_text\"].apply(\n",
    "    detect_language\n",
    ")\n",
    "\n",
    "print(data_puskesmas[\"language\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language id:\n",
      "layan pol kia bagusinformatif anak imunisasi anak reweltidak kooperatif layan sabar tata rumah tangan post imunisasi terima kasih nakesnya\n",
      "\n",
      "Language ms:\n",
      "rasai lahir disinimasyaallah banget bantu banget alhamdulillah normal adek bayi sehat pas lahir drama terima kasih tugas medis barokallah\n",
      "\n",
      "Language en:\n",
      "layan ribetbertele tele sat set awai main handphone\n",
      "\n",
      "Language hu:\n",
      "layan jelek dokter lambat pol antri banget\n",
      "\n",
      "Language nl:\n",
      "ruwet mbak antre judes layan buruk buruk\n",
      "\n",
      "Language eu:\n",
      "layan burukk\n",
      "\n",
      "Language ca:\n",
      "layan sesuai jam antre\n",
      "\n",
      "Language tr:\n",
      "layan puas\n",
      "\n",
      "Language fi:\n",
      "layan buruk vaksin sulit jarak vaksin vaksin sulit cek peduli lindung hak terima vaksin booster\n",
      "\n",
      "Language lt:\n",
      "buka ta puskesmas e\n",
      "\n",
      "Language eo:\n",
      "puskesmas oke sdmnya oke\n",
      "\n",
      "Language es:\n",
      "oke\n",
      "\n",
      "Language ceb:\n",
      "tugas bantu ramah\n",
      "\n",
      "Language min:\n",
      "pegawai ramah antre nomer eh sakit olah olah remeh\n",
      "\n",
      "Language sv:\n",
      "layan puas sesuai moto nya\n",
      "\n",
      "Language pt:\n",
      "puskesmas direnovasiagar bangun\n",
      "\n",
      "Language tl:\n",
      "maaf yaabirokrasi nya ruwet sihmasa surat rujuk antre lmakin kesini ruwet surat rujuk periksa lo harap kaji ulang deh atur\n",
      "\n",
      "Language jv:\n",
      "vaksin suntik vaksin cepat data entrynya\n",
      "\n",
      "Language sr:\n",
      "moga\n",
      "\n",
      "Language it:\n",
      "bidan cantik\n",
      "\n",
      "Language sl:\n",
      "mbak\n",
      "\n",
      "Language sk:\n",
      "obat\n",
      "\n",
      "Language et:\n",
      "bantu pindah faskes\n",
      "\n",
      "Language pl:\n",
      "layan tata rapi\n",
      "\n",
      "Language su:\n",
      "bantu\n",
      "\n",
      "Language no:\n",
      "sedia vaksin booster pakbuk\n",
      "\n",
      "Language de:\n",
      "banguss\n",
      "\n",
      "Language fr:\n",
      "lumayan oke\n",
      "\n",
      "Language ro:\n",
      "bidan din raddinan ramah ramah nyaman dedih binih\n",
      "\n",
      "Language sq:\n",
      "anc padu iya\n",
      "\n",
      "Language war:\n",
      "ngangenin karyawannya\n",
      "\n",
      "Language nds:\n",
      "harga pasien warga\n",
      "\n",
      "Language lv:\n",
      "puskesmas layan buruk\n",
      "\n",
      "Language la:\n",
      "layan mantap\n",
      "\n",
      "Language sw:\n",
      "jumat jam layan tulis layan alas pagiklo pagi iya tulis ganti buka pagi\n",
      "\n",
      "Language cy:\n",
      "puskesmas ramah layan gwl\n",
      "\n",
      "Language bo:\n",
      "sip\n",
      "\n",
      "Language da:\n",
      "top banget\n",
      "\n",
      "Language ga:\n",
      "agus\n",
      "\n",
      "Language nn:\n",
      "rama habis vaksin\n",
      "\n",
      "Language hr:\n",
      "layan sesuai prosedur\n",
      "\n",
      "Language ja:\n",
      "usg nya\n",
      "\n",
      "Language ht:\n",
      "layan nan\n",
      "\n",
      "Language oc:\n",
      "tinjau pas larang bocor\n",
      "\n",
      "Language ur:\n",
      "puskesmas klampis ngasem okdlm layan kiprah masyarakat\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lang in data_puskesmas[\"language\"].unique():\n",
    "    print(f\"Language {lang}:\")\n",
    "    print(\n",
    "        data_puskesmas[data_puskesmas[\"language\"] == lang][\"cleaned_review_text\"].iloc[\n",
    "            0\n",
    "        ]\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating distribution before removing non-Indonesian reviews: \n",
      "rating\n",
      "5    6105\n",
      "1    3162\n",
      "4     609\n",
      "2     436\n",
      "3     389\n",
      "Name: count, dtype: int64\n",
      "Rating distribution after removing non-Indonesian reviews: \n",
      "rating\n",
      "5    5366\n",
      "1    2914\n",
      "4     543\n",
      "2     403\n",
      "3     349\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ms = Malay\n",
    "id = Indonesian\n",
    "en = English\n",
    "jv = Javanese\n",
    "\"\"\"\n",
    "\n",
    "closes_lang = [\"ms\", \"id\", \"en\", \"jv\"]\n",
    "\n",
    "print(\n",
    "    f\"Rating distribution before removing non-Indonesian reviews: \\n{data_puskesmas['rating'].value_counts()}\"\n",
    ")\n",
    "\n",
    "data_puskesmas = data_puskesmas[data_puskesmas[\"language\"].isin(closes_lang)]\n",
    "\n",
    "print(\n",
    "    f\"Rating distribution after removing non-Indonesian reviews: \\n{data_puskesmas['rating'].value_counts()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "from fasttext import FastText\n",
    "\n",
    "model_id = FastText.load_model(\"cc.id.300.bin\")\n",
    "vocab_id = model_id.get_words()\n",
    "\n",
    "words = list(vocab_id)\n",
    "w_rank = {}\n",
    "\n",
    "for idx, word in enumerate(words):\n",
    "    w_rank[word] = idx\n",
    "\n",
    "WORDS = w_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "class SpellingCorrector:\n",
    "    \"\"\"A class for correcting spelling errors in text.\"\"\"\n",
    "\n",
    "    def __init__(self, word_rank):\n",
    "        \"\"\"Initialize the SpellingCorrector with a word rank dictionary.\"\"\"\n",
    "        self.word_rank = word_rank\n",
    "        self.letters = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Tokenize the text into words.\"\"\"\n",
    "        return re.findall(r\"\\w+\", text.lower())\n",
    "\n",
    "    def word_probability(self, word):\n",
    "        \"\"\"Return the probability of `word`.\"\"\"\n",
    "        return -self.word_rank.get(word, 0)\n",
    "\n",
    "    def correct_word(self, word):\n",
    "        \"\"\"Correct `word` to the most probable spelling.\"\"\"\n",
    "        return max(self.candidate_words(word), key=self.word_probability)\n",
    "\n",
    "    def candidate_words(self, word):\n",
    "        \"\"\"Generate candidate words that may be correct spellings of `word`.\"\"\"\n",
    "        return (\n",
    "            self.known_words([word])\n",
    "            or self.known_words(self.edit_distance_one(word))\n",
    "            or self.known_words(self.edit_distance_two(word))\n",
    "            or [word]\n",
    "        )\n",
    "\n",
    "    def known_words(self, words):\n",
    "        \"\"\"Filter `words` to only include words known in the word rank dictionary.\"\"\"\n",
    "        return set(w for w in words if w in self.word_rank)\n",
    "\n",
    "    def edit_distance_one(self, word):\n",
    "        \"\"\"Create words with an edit distance of one from `word`.\"\"\"\n",
    "        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "        deletes = [L + R[1:] for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "        replaces = [L + c + R[1:] for L, R in splits if R for c in self.letters]\n",
    "        inserts = [L + c + R for L, R in splits for c in self.letters]\n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "    def edit_distance_two(self, word):\n",
    "        \"\"\"Create words with an edit distance of two from `word`.\"\"\"\n",
    "        return (\n",
    "            e2\n",
    "            for e1 in self.edit_distance_one(word)\n",
    "            for e2 in self.edit_distance_one(e1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell_corrector = SpellingCorrector(WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d922da7b3cf4d638322f11cec6500b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9575 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def correct_spelling(text):\n",
    "    return \" \".join([spell_corrector.correct_word(word) for word in text.split()])\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "data_puskesmas[\"cleaned_review_text\"] = data_puskesmas[\n",
    "    \"cleaned_review_text\"\n",
    "].progress_apply(correct_spelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in data_puskesmas: 9575\n",
      "Number of rows in data_puskesmas: 9026\n"
     ]
    }
   ],
   "source": [
    "# remove rows with review_text less than 10 characters\n",
    "print(f\"Number of rows in data_puskesmas: {data_puskesmas.shape[0]}\")\n",
    "\n",
    "data_puskesmas = data_puskesmas[data_puskesmas[\"cleaned_review_text\"].str.len() > 10]\n",
    "\n",
    "print(f\"Number of rows in data_puskesmas: {data_puskesmas.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the cleaned data\n",
    "data_puskesmas.to_csv(\"preprocessed-review.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
